---
title: "Fresno RIPA Data Project"
subtitle: "Stop Duration Outlier Analysis"
author: "Catalyst California"
output:
  html_document:
    css: "W:\\RDA Team\\R\\cc_brandguide.css"
    toc: yes
    toc_depth: 2
    toc_float: yes
    code_folding: hide
date: "`r format(Sys.time(), '%d %B, %Y')`"
---

Part of the analysis of RIPA data from the Fresno Police Department for this project is to examine how long Fresno PD officers are spending on different types of police stops. This requires a separate stop duration outlier analysis in order to control for stop duration times that are clear outliers in the data. These outliers can be due to data entry error or an officer forgetting to input a stop time and allowing the timer to run on after the stop has concluded. 

The goal of this outlier analysis is to identify which stops have stop duration times that are outliers, and then cap those stop duration times appropriately. We do this using a regression model that controls for various factors that influence a stop duration time. 

# Load in data and create stop-level data set

```{r setup, include=FALSE}

knitr::opts_chunk$set(comment = FALSE, message = FALSE, warning = FALSE)


library(broom)
library(RPostgreSQL)
library(dplyr)
library(tidyr)
library(tidyverse)
library(stringr)
library(chron)
library(foreign)
library(MASS)
require(foreign)
require(nnet)
require(ggplot2)
require(reshape2)
library(fastDummies)
library(olsrr)
library(rlang)
library(Hmisc)
library(caTools)
library(corrplot)
library(car)
library(quantmod)
library(Hmisc)
library(ggcorrplot)
library(corrplot)
library(jtools)
library(gtsummary)
library(lubridate)
library(formattable)
library(flextable)
library(sf)
library(sp)

#Connect to postgres

source("W:\\RDA Team\\R\\credentials_source.R")

con <- connect_to_db("eci_fresno_ripa")

# Pull in tables from postgres that we need

stops<-dbGetQuery(con, "SELECT * FROM rel_stops")
persons<-dbGetQuery(con, "SELECT * FROM rel_persons") #person-level, has age
race<-dbGetQuery(con, "SELECT * FROM rel_stops_race") #stop-level
reason<-dbGetQuery(con, "SELECT * FROM rel_stops_reason")
result<-dbGetQuery(con, "SELECT * FROM rel_stops_result")
action<-dbGetQuery(con, "SELECT * FROM rel_stops_actions")
action_person <- dbGetQuery(con, "SELECT * FROM rel_persons_actions")
contra<-dbGetQuery(con, "SELECT * FROM rel_stops_searches")
age_df<-dbGetQuery(con, "SELECT * FROM rel_age")

#### Prep age-data ####

# Make age a continuous variable. 

age_df$age <- as.numeric(age_df$age)

# Then take the age table and for stops with multiple people, taking the average age of all persons stopped
  ### Filtered for stop # U1005220184CFBA61E85 (3 persons stopped) in both person-level age df and stop-level df to ensure correct mean age values

age_stop <- age_df %>%
  group_by(stop_id) %>%
  mutate(age_avg = mean(age)) %>%
  slice(1) %>%
  select(stop_id, age_avg)

# now we have a stops-level age table

### Prep stop-level actions data ###

# Need to add more dummy variables for different actions to stop-level actions data

  ## Group by stop_id and slice to remove duplicate stop data
  ## Ensure every dummy action variable takes on value of 1 if action was taken for any of the people
    ### Filtered for stop # U1005220184CFBA61E85 (3 persons stopped) to ensure all values were correctly  assigned
  ## Select to remove variable already in stop-level data set

action_more<-action_person %>%
   group_by(stop_id) %>%
    mutate(across(removed_from_vehicle:ads_written_statement, max)) %>%
  slice(1) %>%
  select(-person_number, -actions_count, -action_taken,
         -removed_from_vehicle, -handcuffed, -detained, -use_of_force)
  
### Prep stop-level gender data ###

gender <- persons %>%
      select(stop_id, g_male, g_female, g_transgender_man, g_transgender_woman, 
         g_gender_nonconforming, g_multigender)%>%
  group_by(stop_id) %>%
  mutate(across(everything(), max)) %>%
  slice(1)

### Join all stops-level data ###

stops<-stops%>%
  left_join(reason)%>%
  left_join(result)%>%
  left_join(action)%>%
  left_join(race)%>%
  left_join(age_stop)%>%
  left_join(action_more)%>%
  left_join(contra) %>%
  left_join(gender) # we should end up with 5317 obs which is how many unique stops there are 

# Remove columns not needed for analysis

stops<-stops%>%
  select(-agency_ori, -agency_name, -school_code, -school_name, -closest_city)

#### Recode NAs ####

# Check for NAs

sum(is.na(stops)) #0 NAs

```

# Creating dummy version of stop-level data

```{r}

#### Create dummy version of stop table  ####

# Categorical variables need to become separate 1/0 dummy columns for the model

stops_d<-stops%>%
  dummy_cols(select_columns = c("stop_nh_race","stop_reason_simple", "stop_result_simple"))

# clean up the column names remaining

names(stops_d)<- tolower(names(stops_d)) # make all colnames lowercase
colnames(stops_d) = gsub(" ", "_", colnames(stops_d)) # remove all spaces and make underscore
colnames(stops_d) = gsub("-", "", colnames(stops_d)) # remove hyphens

# check no NAs still

sum(is.na(stops_d)) #0

# pull list of new cols

vars_d<-as.data.frame(colnames(stops_d))

# extract dummy columns we are not keeping: these are the reference groups within each larger category (division, race, stop reason, stop result)

vars_remove<-grep("stop_nh_race_nh_white|stop_reason_simple_traffic_violation|stop_result_simple_citation|g_male",  colnames(stops_d))


# then remove the selected dummy variables we are not keeping 
stops_d<-stops_d[,-vars_remove]

# update list of variables in stops_d

vars_d<-as.data.frame(colnames(stops_d))

# rename extra long columns

stops_d<-stops_d%>%
  
  
  ### stop reason cols
  
  rename("stop_reason_simple_consent_search"="stop_reason_simple_consensual_encounter_resulting_in_search")%>%
    rename("stop_reason_simple_truant"="stop_reason_simple_investigation_to_determine_whether_person_was_truant")%>%
    rename("stop_reason_simple_warrant"="stop_reason_simple_knowledge_of_outstanding_arrest/wanted_person")%>%
      rename("stop_reason_simple_parole"="stop_reason_simple_parole/probation/prcs/_mandatory_supervision")%>%
        rename("stop_reason_simple_reasonable_suspicion"="stop_reason_simple_reasonable_suspicion")%>%
          rename("stop_reason_simple_twoormore"="stop_reason_simple_two_or_more_reasons")%>%
  
  ### stop result cols
  
    # rename("stop_result_simple_citation"="stop_result_simple_citation_for_infraction")%>%
   rename("stop_result_simple_guardian"="stop_result_simple_contacted_parent/legal_guardian_or_other_person_responsible_for_minor")%>%
    rename("stop_result_simple_arrest_warrant"="stop_result_simple_custodial_arrest_pursuant_to_outstanding_warrant")%>%
      rename("stop_result_simple_arrest_nowarrant"="stop_result_simple_custodial_arrest_without_warrant")%>%
      rename("stop_result_simple_fieldinterviewcard"="stop_result_simple_field_interview_card_completed")%>%
      rename("stop_result_simple_citerelease"="stop_result_simple_in_field_cite_and_release")%>%
    rename("stop_result_simple_transport"="stop_result_simple_noncriminal_transport_or_caretaking_transport")%>%
      rename("stop_result_simple_psychiatric"="stop_result_simple_psychiatric_hold")%>%
  rename("stop_result_simple_schooladmin"="stop_result_simple_referral_to_school_administrator")%>%
      rename("stop_result_simple_twoormore"="stop_result_simple_two_or_more_results")%>%
    rename("stop_result_simple_warning"="stop_result_simple_warning_verbal_or_written")

# make sure no trailing or empty spaces in colnames

names(stops_d) <- gsub(" ", "", names(stops_d))

# update list of variables in dummy df 

vars_d<-as.data.frame(colnames(stops_d))

```


# Create and run model

Below is a list of the variables we used in this model. Most match the variables used in RIPA outlier analysis for the SD Pillars project. The exception is the removal of officer divisions and beat variables, and the addition of gender action-count-by-stop variables. 

Variable | Type of variable
------------- | -------------
Stop duration | Dependent variable
Stop action | Independent variable
Stop in response to call for service | Independent variable
Age of person stopped | Independent variable (continuous)
Race of person stopped | Independent variable (categorical)
Gender of person stopped | Independent variable (categorical)
Stop reason | Independent variable (categorical)
Stop result | Independent variable (categorical)
Number of people stopped | Independent variable (continuous)
Number of Actions taken during stop | Independent variable (continuous)
Person remove from vehicle | Independent variable (categorical)
Person detained | Independent variable (categorical)
Use of force | Independent variable (categorical)
Person handcuffed | Independent variable (categorical)
Search took place | Independent variable (categorical)
Firearm pointed | Independent variable (categorical)
Sobriety test conducted | Independent variable (categorical)
Removed from vehicle without force | Independent variable (categorical)

The following are the categorical variables that are not already dummy variables (1/0) and require establishing a reference group.

Categorical Variable | Reference group
------------- | -------------
Stop reason | Traffic violation
Stop result | No action
Race of person stopped | NH White
Gender of person stopped | Cis-gender Male

```{r}
model<-lm(log(stop_duration) ~ 
            
call_for_service+
  persons_count+
   # actions_count+
  
action_taken+
  handcuffed+
removed_from_vehicle+
detained+
use_of_force+
    ads_prop_seize+
  contraband_found+
   search+
  # contraband_count+
  ads_sobriety_test+
  # ads_firearm_point+
  # ads_removed_vehicle_order+
  
  age_avg+
    
g_female+
    g_transgender_man+
    g_transgender_woman+
    g_multigender+
    g_gender_nonconforming+

stop_nh_race_latinx +
stop_nh_race_nh_aian+
stop_nh_race_nh_asian+
stop_nh_race_nh_black+
stop_nh_race_nh_multi_race+
  stop_nh_race_nh_multiracial+
stop_nh_race_nh_nhpi+
 stop_nh_race_nh_sswana+

  

stop_reason_simple_consent_search+
stop_reason_simple_truant+
stop_reason_simple_warrant+
stop_reason_simple_parole+
 stop_reason_simple_reasonable_suspicion+
stop_reason_simple_twoormore+

  # stop_result_simple_citation+
stop_result_simple_no_action+
stop_result_simple_guardian+
stop_result_simple_arrest_warrant+
stop_result_simple_arrest_nowarrant+
stop_result_simple_fieldinterviewcard+
stop_result_simple_citerelease+
stop_result_simple_transport+
stop_result_simple_psychiatric+
stop_result_simple_schooladmin+
stop_result_simple_twoormore+
  stop_result_simple_warning,

            data = stops_d)

```

## VIF Values

Test for multicollinearity among independent variables: calculate Variance Influence Factor (VIF) scores of independent variables in model
    + As a rule of thumb, a VIF value that exceeds 5 or 10 indicates a problematic amount of collinearity (James et al. 2014).
    
```{r}

# Test for multicolinearity: Visualize variance influence factors (VIF) 

vif_values <- vif(model) 

vif_values 

# revisions

# actions_count--captured in action_taken, 
# ads_removed_vehicle_order--captured in removed_from_vehicle
# stop_result_simple_citation--make reference because it's a larger category
# ads_firearm_point--captured in use of force
# contraband_count--captured in contraband found
# ads_prop_seize--captured in contraband_found

```

## Regression Summary

The regression summary table shows us the p values for all our independent variables. Note some have high p values (>.10) and are therefore not statistically significant at a 90% confidence interval. This could be because these variables have a small n, or these variables do not occur often. 

The current model has a R^2 of 52% which is a good indication that our model is robust. This means that 52% of variance in stop duration times is explained by our model. 

Also note that the current model has 0 NA or missing values. This is the result of data cleaning and recoding done prior running the model. Specifically, NA values from people who were preceived as 6 or more races, and NA values from unknow SDPD divisions were all recoded accordingly to avoid NA values in the model. 

The diagnostic plots give us a sense of how robust our working model is and if any adjustments are needed. See this [reference link for understanding diagnostic plots](http://www.sthda.com/english/articles/39-regression-model-diagnostics/161-linear-regression-assumptions-and-diagnostics-in-r-essentials/#:~:text=Regression%20diagnostics%20plots%20can%20be,creates%20a%20ggplot2%2Dbased%20graphics.&text=The%20diagnostic%20plots%20show%20residuals,check%20the%20linear%20relationship%20assumptions.) and what we want them to look like in order to feel confident about our model.

```{r}
#summarize result 

summ(model) 

# plot diagnostics
par(mfrow=c(2,2))
plot(model)

```

# Identifying Outliers 

We use these guiding rules to determine which stop duration times are outliers from our model:

Key reference material: Belsley, D.A.; Kuh, E., Welsh, R. E. (1980). Regression Diagnostics: Identifying Influential Data and Sources of Collinearity. Rules of Thumb" used to identify potential outliers: (k=number of IVs; N= Sample size) NOTE: These ‘rules’ are not a hard-and-fast rule, but rather a guideline only! ALWAYS produce a plot/histogram or sample quantiles of your outlier measures

Measure	Cut-off Value:

* abs(standardized resid)	> 2 (or 3)
* leverage	>(2k,2)/N
* abs(Dffits)	> 2/sqrt(k,1/N)
* abs(Dfbetas)	> 2/sqrt(N)
* Cook’s D	> 4/N

Source: http://rstudio-pubs-static.s3.amazonaws.com/477250_8b19e334ad1245c9b9259e9c5db36089.html#7_identifying_outliers


```{r}

# reference: http://rstudio-pubs-static.s3.amazonaws.com/477250_8b19e334ad1245c9b9259e9c5db36089.html#7_identifying_outliers 

# calculate each unit of measure for outlier threshold analysis 

model_all_metrics <- augment(model) 

```


# Identifying and Capping outliers using Predictive Interval

* Resource, CI vs Predicted Interval: https://towardsdatascience.com/confidence-intervals-vs-prediction-intervals-7b296ae58745
* Resource: https://rpubs.com/aaronsc32/regression-confidence-prediction-intervals

```{r}

#### Calculate Predicted Value (pv) and Predicted Value Confidence Intervals####

 # Create a dataframe that has a identifier value column we will use to add in the predicted values

pv<-stops%>%
  select(stop_id)

# Then calculate the predicted value of stop_duration. Because this is a logarithmic model, the predicted values are logs

pv[c("pv_log", "lwr_log", "upr_log")]<-predict(model, newdata=stops_d, interval="prediction")

# Add a new column taking the inverse of the logarithmic predicted value and confidence intervals to revert stop_time and CI predicted values to non-log form

pv<-pv%>%mutate(pv=exp(pv_log),
                          lwr=exp(lwr_log),
                          upr=exp(upr_log))

# join the pv table to stops table

stops<-stops%>%
  left_join(pv, by = c("stop_id" = "stop_id"))

  ## all analysis variables appear duplicated with column header ".x" and ".y"
  # Rename ".x" columns to remove the ".x"

# stops <- stops %>%
#   rename("pv" = pv.x,
#          "lwr" = lwr.x, 
#          "upr" = upr.x, 
#          "pv_log" = pv_log.x, 
#          "lwr_log" = lwr_log.x, 
#          "upr_log" = upr_log.x)

# select columns of interest

final_cap<-stops%>%
select(c("stop_id", "stop_duration", "pv", "lwr", "upr", "pv_log", "upr_log", "lwr_log"))

#### Determine outlier based off lwr and upr prediction value intervals ####

# create column indicating if that row requires a upper or lower cap, then implement cap

final_cap<-final_cap%>%
 mutate(cap_type=ifelse(stop_duration>upr, "high",
                         ifelse(stop_duration<lwr, "low", "none")))%>%
  mutate(stop_duration_capped=ifelse(cap_type=="high", upr,
                              ifelse(cap_type=="low", lwr,
                                     stop_duration)))

# rearrange column order 

col_order <- c("stop_id", "stop_duration", "stop_duration_capped", "cap_type",  "pv", "lwr","upr", "pv_log", "lwr_log", "upr_log")

final_cap <- final_cap[, col_order]

#### Explore results: ####

# table(final_cap$cap_type)

# sum(is.na(final_cap$stop_duration_capped)) # 0 NAs

high<-final_cap%>%
  filter(cap_type=='high')

low<-final_cap%>%
  filter(cap_type=='low')

```

# Descriptive Stats Testing

Take the stop duration capped values created using the Predicted Value Confidence Interval method and run some descriptive stats 

## Original Stop Times: Officer-initiated Stop Counts and Time Stats for Fresno PD

```{r}

# prep data 

df <- stops %>%
  select(stop_id, call_for_service, stop_duration) %>%
  mutate(Total = sum(stop_duration, na.rm = TRUE)) %>%
  group_by(call_for_service) %>%
  mutate(Count = sum(stop_duration, na.rm = TRUE),
         'Percent Mins' = Count/Total*100,
         'Average Stop Time (Mins)' = mean(stop_duration, na.rm = FALSE),
         'Median Stop Time (Mins)' = median(stop_duration, na.rm = FALSE),
         'Min Stop Time (Mins)' = min(stop_duration, na.rm = FALSE),
         'Max Stop Time (Mins)' = max(stop_duration, na.rm = FALSE),
         'Total Time (Mins)' = Total,
         'Count Mins' = Count
  ) %>%
  slice(1) %>%
  select(-c(stop_id, stop_duration, Count, Total)) %>%
  mutate(call_for_service = ifelse(call_for_service %in% 0, 'No', 'Yes')) %>%
  rename('Call for Service' = 'call_for_service') %>%
  relocate('Count Mins', .after = 'Call for Service')

# Create and style flextable
df %>% 
  flextable() %>% 
  colformat_double(j = c("Count Mins", "Percent Mins", "Average Stop Time (Mins)", 'Median Stop Time (Mins)',
                         'Min Stop Time (Mins)', 'Max Stop Time (Mins)', 'Total Time (Mins)'), digits = 1) %>% 
  set_caption('Original Times: Stop Time by Response to Service Call for Fresno PD (2022)') %>% 
  theme_vanilla()

```

## With Capped Stop Times: Officer-initiated Stop Counts and Time Stats across All Units

```{r}

df<-stops%>%
  select(stop_id, call_for_service, stop_duration)%>%
  left_join(final_cap)%>%
  mutate(Total=sum(stop_duration_capped,na.rm=TRUE))%>%
  group_by(call_for_service)%>%
  mutate(Count=sum(stop_duration_capped,na.rm=TRUE),
         'Percent Mins'=Count/Total*100,
         'Average Stop Time (Mins)' = mean(stop_duration_capped, na.rm = FALSE),
            'Median Stop Time (Mins)'=   median(stop_duration_capped,na.rm = FALSE),
             'Min Stop Time (Mins)'=min(stop_duration_capped,na.rm = FALSE),
            'Max Stop Time (Mins)'=max(stop_duration_capped,na.rm = FALSE),
             'Total Time (Mins)'= Total,
         'Count Mins'=Count
         )%>%
  slice(1)%>%
  select(2, 14:20)%>%
  mutate(call_for_service=ifelse(call_for_service %in% 0, 'No', 'Yes'))%>%
    rename('Call for Service'='call_for_service')%>%
     relocate('Count Mins', .after = 'Call for Service')

         
#create and style flextable

  flextable(df) %>% 
colformat_double(j = c("Count Mins", "Percent Mins", "Average Stop Time (Mins)",'Median Stop Time (Mins)',
                       'Min Stop Time (Mins)','Max Stop Time (Mins)', 'Total Time (Mins)'), digits = 1)%>% 
  set_caption('Capped Times: Stop Time by Response to Service Call, Fresno PD (2022)') %>% 
  theme_vanilla() 

```


# Create postgres table

```{r, include=FALSE, eval=FALSE}

#### Finalize Table and Push to Postgres ####

# dont need the log pv/lwr/upr values

df_final<-final_cap%>%
  select(1:7)

# make sure no trailing spaces anywhere

names(df_final) <- gsub(" ", "", names(df_final))

df_final[df_final == " "] <- ""

# set column types

charvect = rep("numeric", ncol(df_final)) #create vector that is "varchar" for the number of columns in df

charvect <- replace(charvect, c(1,4), c("varchar"))

# add df colnames to the character vector

names(charvect) <- colnames(df_final)

# push to postgres

table_name <- "rel_stop_duration_capped"
schema <- 'data'

dbWriteTable(con, c(schema, table_name), df_final, 
             overwrite = TRUE, row.names = FALSE,
             field.types = charvect)

# add meta data

table_comment <- paste0("COMMENT ON TABLE rel_stop_duration_capped  IS 'Table by unique stop ID of stops and stop duration times with lower and upper stop duration outliers flagged and capped using upper and lower predicted interval threshold values of stop duration predicted value. All stops are from 2022. Variables that are used to cap the stop duration times are:  
Variable | Type of variable
------------- | -------------
Stop duration | Dependent variable
Stop action | Independent variable
Stop in response to call for service | Independent variable
Age of person stopped | Independent variable (continuous)
Race of person stopped | Independent variable (categorical)
Gender of person stopped | Independent variable (categorical)
Stop reason | Independent variable (categorical)
Stop result | Independent variable (categorical)
Number of people stopped | Independent variable (continuous)
Number of Actions taken during stop | Independent variable (continuous)
Person remove from vehicle | Independent variable (categorical)
Person detained | Independent variable (categorical)
Use of force | Independent variable (categorical)
Person handcuffed | Independent variable (categorical)
Search took place | Independent variable (categorical)
Firearm pointed | Independent variable (categorical)
Sobriety test conducted | Independent variable (categorical)
Removed from vehicle without force | Independent variable (categorical)

Full methodology can be found in R script: W:\\Project\\ECI\\Fresno RIPA\\GitHub\\IB\\fresnoripa\\outlier_analysis\\outlier_analysis.rmd
QA document: 
W:\\Project\\ECI\\Fresno RIPA\\Documentation\\QA_outlier_analysis_docx.';

COMMENT ON COLUMN rel_stop_duration_capped.stop_id IS 'Stop ID';
COMMENT ON COLUMN rel_stop_duration_capped.stop_duration IS 'Original stop duration';
COMMENT ON COLUMN rel_stop_duration_capped.stop_duration_capped IS 'Stop duration where outlier stop durations have either a lower or higher cap implemented. If stop has a stop duration that is not an outlier than the original stop duration is used.';
COMMENT ON COLUMN rel_stop_duration_capped.cap_type IS 'Flag if stop duration time cap is a upper or lower cap. This only applies to stop durations that were outliers. If the stop duration was an outlier and the stop duration time > predicted value upper predicted interval threshold value, then it is an upper cap type. If the stop duration time < predicted value of the lower predicted interval threshold value, then it is a lower cap type.';
COMMENT ON COLUMN rel_stop_duration_capped.pv IS 'Predicted Value of the Stop Duration using Logistic Regression Model. Refer to QA doc for full methodology on how model was made. ';
COMMENT ON COLUMN rel_stop_duration_capped.upr IS 'Predicted value predicted interval upper value';
COMMENT ON COLUMN rel_stop_duration_capped.lwr IS 'Predicted value predicted interval lower value';
;")

# send table comment + column metadata
dbSendQuery(con = con, table_comment)

# add indices

dbSendQuery(con, paste0("create index rel_stop_duration_capped_stop_id on data.rel_stop_duration_capped (stop_id);"))




```